{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surfaces: Test Functions for Optimization\n",
    "\n",
    "A quick introduction to benchmarking optimization algorithms.\n",
    "\n",
    "**What you'll learn:**\n",
    "- What test functions are and why they matter\n",
    "- How to use Surfaces in just a few lines of code\n",
    "- How to visualize optimization landscapes\n",
    "- Practical tips for benchmarking optimizers\n",
    "\n",
    "**Prerequisites:**\n",
    "- Python basics (functions, dictionaries, loops)\n",
    "- NumPy fundamentals\n",
    "- No prior knowledge of optimization required\n",
    "\n",
    "**Time to complete:** ~15 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Install Surfaces with visualization support, then import the modules we'll use throughout this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to install:\n",
    "# !pip install surfaces[viz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports for this notebook\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from surfaces import presets\n",
    "from surfaces.test_functions import (\n",
    "    AckleyFunction,\n",
    "    EggholderFunction,\n",
    "    HimmelblausFunction,\n",
    "    RastriginFunction,\n",
    "    RosenbrockFunction,\n",
    "    SphereFunction,\n",
    ")\n",
    "from surfaces.visualize import plot_contour, plot_surface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Why Test Functions?\n",
    "\n",
    "When developing optimization algorithms, you need reliable ways to test them. Real-world problems are often expensive to evaluate, hard to visualize, and lack a known optimal solution.\n",
    "\n",
    "**Test functions** solve these problems:\n",
    "\n",
    "| Property | Benefit |\n",
    "|----------|--------|\n",
    "| Known global optimum | Measure how close your optimizer gets |\n",
    "| Fast evaluation | Run thousands of experiments quickly |\n",
    "| Diverse characteristics | Test different algorithm weaknesses |\n",
    "| Standardized | Compare results with published research |\n",
    "\n",
    "Surfaces provides **50+ test functions** ready to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Your First Test Function\n",
    "\n",
    "The **Sphere function** is the simplest test case: just the sum of squared values. The minimum is at the origin where all parameters equal zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sphere = SphereFunction(n_dim=2)\n",
    "\n",
    "# Functions are callable - just pass parameters\n",
    "print(f\"f(1, 2) = {sphere({'x0': 1.0, 'x1': 2.0})}\")\n",
    "print(f\"f(0, 0) = {sphere({'x0': 0.0, 'x1': 0.0})}  <- global minimum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flexible Input Formats\n",
    "\n",
    "Surfaces accepts whatever format fits your workflow. All of these produce the same result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sphere = SphereFunction(n_dim=2)\n",
    "\n",
    "print(\"Dictionary: \", sphere({\"x0\": 1.0, \"x1\": 2.0}))\n",
    "print(\"NumPy array:\", sphere(np.array([1.0, 2.0])))\n",
    "print(\"Python list:\", sphere([1.0, 2.0]))\n",
    "print(\"Kwargs:     \", sphere(x0=1.0, x1=2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Visualizing Landscapes\n",
    "\n",
    "Understanding an optimization landscape visually reveals why some problems are harder than others. Surfaces includes built-in plotting with Plotly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Sphere: A Simple Bowl\n",
    "\n",
    "Smooth and convex. Any gradient-based optimizer finds the minimum easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_surface(SphereFunction(n_dim=2), resolution=60)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Rastrigin: Many Local Minima\n",
    "\n",
    "Same global minimum at the origin, but surrounded by traps. Tests an optimizer's ability to escape local optima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_surface(RastriginFunction(n_dim=2), resolution=80)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Ackley: Deceptive Plateau\n",
    "\n",
    "A flat outer region with a deep hole at the center. Many optimizers get stuck on the plateau, never finding the global minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_surface(AckleyFunction(), resolution=80)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contour Plots\n",
    "\n",
    "2D contour plots are often easier to read. The **Rosenbrock function** (the \"banana valley\") has its minimum at (1, 1), but the narrow curved valley makes optimization difficult."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_contour(RosenbrockFunction(n_dim=2), resolution=100)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Function Gallery\n",
    "\n",
    "Different functions test different optimizer capabilities. Here's a side-by-side comparison of four common test functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    (SphereFunction(n_dim=2), \"Sphere (Easy)\"),\n",
    "    (RastriginFunction(n_dim=2), \"Rastrigin (Many Traps)\"),\n",
    "    (AckleyFunction(), \"Ackley (Deceptive)\"),\n",
    "    (HimmelblausFunction(), \"Himmelblau (4 Minima)\"),\n",
    "]\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2,\n",
    "    cols=2,\n",
    "    specs=[[{\"type\": \"surface\"}] * 2] * 2,\n",
    "    subplot_titles=[name for _, name in functions],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (func, _) in enumerate(functions):\n",
    "    row, col = idx // 2 + 1, idx % 2 + 1\n",
    "    space = func.search_space\n",
    "    names = sorted(space.keys())\n",
    "    x, y = space[names[0]], space[names[1]]\n",
    "\n",
    "    z = np.array([[func({names[0]: xi, names[1]: yi}) for xi in x] for yi in y])\n",
    "    func.reset()\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Surface(x=x, y=y, z=z, colorscale=\"Viridis\", showscale=False), row=row, col=col\n",
    "    )\n",
    "\n",
    "fig.update_layout(height=700, width=800, title_text=\"Test Function Gallery\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Automatic Data Collection\n",
    "\n",
    "One of Surfaces' most useful features: every evaluation is automatically tracked. No manual bookkeeping needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = RastriginFunction(n_dim=2)\n",
    "\n",
    "# Simulate random search\n",
    "np.random.seed(42)\n",
    "for _ in range(100):\n",
    "    func({\"x0\": np.random.uniform(-5, 5), \"x1\": np.random.uniform(-5, 5)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Evaluations:  {func.n_evaluations}\")\n",
    "print(f\"Best score:   {func.best_score:.4f}\")\n",
    "print(f\"Best params:  x0={func.best_params['x0']:.3f}, x1={func.best_params['x1']:.3f}\")\n",
    "print(f\"True optimum: {func.f_global}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Search History\n",
    "\n",
    "The `search_data` attribute contains the complete evaluation history as a list of dictionaries. We can visualize where the optimizer explored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(func.search_data)\n",
    "df[\"eval_num\"] = range(len(df))\n",
    "\n",
    "fig = plot_contour(RastriginFunction(n_dim=2), resolution=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add search points\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df[\"x0\"],\n",
    "        y=df[\"x1\"],\n",
    "        mode=\"markers\",\n",
    "        marker=dict(\n",
    "            size=8,\n",
    "            color=df[\"eval_num\"],\n",
    "            colorscale=\"Reds\",\n",
    "            showscale=True,\n",
    "            colorbar=dict(title=\"Eval #\"),\n",
    "        ),\n",
    "        name=\"Search Points\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Mark best found\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[func.best_params[\"x0\"]],\n",
    "        y=[func.best_params[\"x1\"]],\n",
    "        mode=\"markers\",\n",
    "        marker=dict(size=15, color=\"lime\", symbol=\"star\"),\n",
    "        name=\"Best Found\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Mark true optimum\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[0],\n",
    "        y=[0],\n",
    "        mode=\"markers\",\n",
    "        marker=dict(size=15, color=\"white\", symbol=\"x\"),\n",
    "        name=\"True Optimum\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(title=\"Random Search on Rastrigin\", width=650, height=550)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Search Space\n",
    "\n",
    "Every function provides a `search_space` property: a dictionary mapping parameter names to arrays of valid values. This integrates directly with optimization libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = AckleyFunction()\n",
    "\n",
    "for name, values in func.search_space.items():\n",
    "    print(f\"{name}: {len(values)} values in [{values.min():.1f}, {values.max():.1f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Higher dimensions work the same way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_10d = SphereFunction(n_dim=10)\n",
    "print(f\"Parameters: {list(func_10d.search_space.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Memory Caching\n",
    "\n",
    "Many optimizers evaluate the same point multiple times. Enable `memory=True` to cache results and avoid redundant computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate expensive evaluation with 10ms delay\n",
    "func_slow = SphereFunction(n_dim=2, sleep=0.01)\n",
    "func_cached = SphereFunction(n_dim=2, sleep=0.01, memory=True)\n",
    "\n",
    "point = {\"x0\": 1.0, \"x1\": 2.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without cache: 10 evaluations\n",
    "start = time.time()\n",
    "for _ in range(10):\n",
    "    func_slow(point)\n",
    "time_slow = time.time() - start\n",
    "\n",
    "# With cache: 1 evaluation + 9 cache hits\n",
    "start = time.time()\n",
    "for _ in range(10):\n",
    "    func_cached(point)\n",
    "time_cached = time.time() - start\n",
    "\n",
    "print(f\"Without cache: {time_slow:.3f}s\")\n",
    "print(f\"With cache:    {time_cached:.3f}s\")\n",
    "print(f\"Speedup:       {time_slow/time_cached:.0f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Comparing Optimizers\n",
    "\n",
    "Here's a practical example: comparing two simple optimization strategies using Surfaces' automatic data collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search(func, n_iter=200):\n",
    "    \"\"\"Sample random points from the search space.\"\"\"\n",
    "    space = func.search_space\n",
    "    for _ in range(n_iter):\n",
    "        params = {k: np.random.choice(v) for k, v in space.items()}\n",
    "        func(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hill_climb(func, n_iter=200, step=0.1):\n",
    "    \"\"\"Start random, then take small improving steps.\"\"\"\n",
    "    space = func.search_space\n",
    "    current = {k: np.random.choice(v) for k, v in space.items()}\n",
    "    current_score = func(current)\n",
    "\n",
    "    for _ in range(n_iter - 1):\n",
    "        candidate = {\n",
    "            k: np.clip(current[k] + np.random.uniform(-step, step), space[k].min(), space[k].max())\n",
    "            for k in space\n",
    "        }\n",
    "        score = func(candidate)\n",
    "        if score < current_score:\n",
    "            current, current_score = candidate, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run comparison\n",
    "results = []\n",
    "for FuncCls, name in [(SphereFunction, \"Sphere\"), (RastriginFunction, \"Rastrigin\")]:\n",
    "    for opt, opt_name in [(random_search, \"Random\"), (hill_climb, \"Hill Climb\")]:\n",
    "        np.random.seed(42)\n",
    "        func = FuncCls(n_dim=2)\n",
    "        opt(func)\n",
    "        results.append(\n",
    "            {\n",
    "                \"Function\": name,\n",
    "                \"Optimizer\": opt_name,\n",
    "                \"Best\": func.best_score,\n",
    "                \"Optimum\": func.f_global,\n",
    "            }\n",
    "        )\n",
    "\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convergence Plot\n",
    "\n",
    "Track how quickly each optimizer improves over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "for opt, name, color in [(random_search, \"Random\", \"blue\"), (hill_climb, \"Hill Climb\", \"red\")]:\n",
    "    np.random.seed(42)\n",
    "    func = RastriginFunction(n_dim=2)\n",
    "    opt(func)\n",
    "\n",
    "    scores = [d[\"score\"] for d in func.search_data]\n",
    "    best_so_far = np.minimum.accumulate(scores)\n",
    "    fig.add_trace(go.Scatter(y=best_so_far, mode=\"lines\", name=name, line=dict(color=color)))\n",
    "\n",
    "fig.add_hline(y=0, line_dash=\"dash\", line_color=\"green\", annotation_text=\"Optimum\")\n",
    "fig.update_layout(\n",
    "    title=\"Convergence on Rastrigin\",\n",
    "    xaxis_title=\"Evaluations\",\n",
    "    yaxis_title=\"Best Score\",\n",
    "    yaxis_type=\"log\",\n",
    "    width=650,\n",
    "    height=400,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Pre-defined Suites\n",
    "\n",
    "Surfaces includes curated function collections for standardized benchmarking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Available presets:\")\n",
    "print(f\"  quick:    {len(presets.suites.quick):2d} functions - smoke tests\")\n",
    "print(f\"  standard: {len(presets.suites.standard):2d} functions - academic benchmarks\")\n",
    "print(f\"  bbob:     {len(presets.suites.bbob):2d} functions - COCO/BBOB competition\")\n",
    "print(f\"  cec2014:  {len(presets.suites.cec2014):2d} functions - CEC 2014 competition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nQuick suite:\")\n",
    "for cls in presets.suites.quick:\n",
    "    print(f\"  - {cls.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Bonus: The Eggholder\n",
    "\n",
    "One of the most challenging test functions, with a highly irregular landscape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_surface(EggholderFunction(), resolution=100)\n",
    "fig.update_layout(title=\"Eggholder Function\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "**Key takeaways:**\n",
    "\n",
    "| Feature | What it does |\n",
    "|---------|-------------|\n",
    "| 50+ functions | Diverse optimization challenges |\n",
    "| Simple API | Callable with dict, array, list, or kwargs |\n",
    "| Auto tracking | `search_data`, `best_score`, `best_params` |\n",
    "| Memory cache | Skip redundant evaluations |\n",
    "| Visualization | Understand landscapes before optimizing |\n",
    "| Presets | Academic and competition benchmarks |\n",
    "\n",
    "**Next steps:**\n",
    "- Explore all functions: `from surfaces.test_functions import *`\n",
    "- Try ML hyperparameter functions (require scikit-learn)\n",
    "- Check engineering design problems with constraints\n",
    "- Add noise to test robustness: `SphereFunction(noise=GaussianNoise(sigma=0.1))`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
